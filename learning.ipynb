{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "1000000\n",
      "2000000\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "import glob\n",
    "import string\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "def get_data(files) :\n",
    "    global i, w, dictionary\n",
    "    data = []\n",
    "    for file in files :\n",
    "        data_file = []\n",
    "        with io.open(file, encoding='utf-8') as f:\n",
    "            text = f.read().lower().encode('utf-8')\n",
    "            words = text.split()\n",
    "            for word in words:\n",
    "                word = word.translate(None, string.punctuation)\n",
    "                w = w + 1\n",
    "                if w % 1000000 == 0 :\n",
    "                    print w\n",
    "                if word in dictionary:\n",
    "                    index = dictionary[word]\n",
    "                else:\n",
    "                    index = i\n",
    "                    dictionary[word] = i\n",
    "                    i = i + 1\n",
    "                data_file.append(index)\n",
    "        data.append(data_file)\n",
    "    return data\n",
    "\n",
    "#Global variables\n",
    "i = 0\n",
    "w = 0\n",
    "dictionary = dict()\n",
    "\n",
    "#standard variables \n",
    "input_dim = 10000\n",
    "\n",
    "# for training data\n",
    "# for neg\n",
    "path1 = './aclImdb/train/neg/*.txt'\n",
    "files = glob.glob(path1)\n",
    "print len(files)\n",
    "train_X = get_data(files)\n",
    "train_Y = np.full((2,len(train_X)),0)\n",
    "train_Y[0,:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "(2, 12500) (2, 12500)\n",
      "(2, 12500) (2, 25000)\n",
      "(2, 25000)\n",
      "12500\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "(2, 12500)\n",
      "12500\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "182730 182730 11557403 25000 25000\n"
     ]
    }
   ],
   "source": [
    "# for pos\n",
    "path1 = './aclImdb/train/pos/*.txt'\n",
    "files = glob.glob(path1)\n",
    "print len(files)\n",
    "train  = get_data(files)\n",
    "y = np.full((2, len(train)), 0)\n",
    "y[1,:] = 1\n",
    "print y.shape, train_Y.shape\n",
    "#print [i for i in y if i == 1]\n",
    "train_Y = np.append(train_Y, y, axis = 1)\n",
    "print y.shape, train_Y.shape\n",
    "\n",
    "#print [i for i in train_Y if i == 1]\n",
    "train_X.extend(train)\n",
    "print train_Y.shape\n",
    "#for testing data\n",
    "#for neg\n",
    "path1 = './aclImdb/test/neg/*.txt'\n",
    "files = glob.glob(path1)\n",
    "print len(files)\n",
    "test_X = get_data(files)\n",
    "test_Y = np.full((2,len(test_X)),0)\n",
    "test_Y[0,:] = 1\n",
    "print test_Y.shape\n",
    "#for pos\n",
    "path1 = './aclImdb/test/pos/*.txt'\n",
    "files = glob.glob(path1)\n",
    "print len(files)\n",
    "test  = get_data(files)\n",
    "y = np.full((2,len(test)), 1)\n",
    "y[1,:] = 1\n",
    "test_Y = np.append(test_Y, y, axis = 1)\n",
    "test_X.extend(test)\n",
    "\n",
    "print len(dictionary), i, w, len(train_X), len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 25000) (2, 25000)\n"
     ]
    }
   ],
   "source": [
    "print train_Y.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###### Get most frequent words\n",
    "\n",
    "popular_words = sorted(dictionary, key = dictionary.get, reverse = False)\n",
    "\n",
    "top = [dictionary[x] for x in popular_words[:input_dim]]\n",
    "\n",
    "for i in range(len(train_X)) :\n",
    "    train_X[i] = [x if x in top else 0 for x in train_X[i]]\n",
    "\n",
    "for i in range(len(test_X)) :\n",
    "    test_X[i] = [x if x in top else 0 for x in test_X[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "25000 25000 <type 'numpy.ndarray'> (2, 25000) (2, 25000)\n",
      "(25000, 2) (25000, 2)\n"
     ]
    }
   ],
   "source": [
    "print len(top)\n",
    "print len(train_X), len(test_X), type(train_Y), train_Y.shape, test_Y.shape\n",
    "train_Y = train_Y.reshape(len(train_Y[1]), 2)\n",
    "test_Y = test_Y.reshape(len(test_Y[1]), 2)\n",
    "print train_Y.shape, test_Y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "\n",
    "# Data preprocessing\n",
    "# Sequence padding\n",
    "trainX = pad_sequences(train_X, maxlen=100, value=0.)\n",
    "testX = pad_sequences(test_X, maxlen=100, value=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Converting labels to binary vectors\n",
    "trainY = to_categorical(train_Y[:, 0], nb_classes=2)\n",
    "testY = to_categorical(test_Y[:, 0], nb_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((25000, 100), (25000, 2), 25000, 25000, (25000, 2))\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape, trainY.shape, len(trainX), len(testY), train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "trainX, TrainY = unison_shuffled_copies(trainX, trainY)\n",
    "testX, testY = unison_shuffled_copies(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 14069  | total loss: \u001b[1m\u001b[32m0.16795\u001b[0m\u001b[0m | time: 178.462s\n",
      "| Adam | epoch: 010 | loss: 0.16795 - acc: 0.9440 -- iter: 22496/22500\n",
      "Training Step: 14070  | total loss: \u001b[1m\u001b[32m0.16283\u001b[0m\u001b[0m | time: 183.914s\n",
      "| Adam | epoch: 010 | loss: 0.16283 - acc: 0.9433 | val_loss: 2.12632 - val_acc: 0.4112 -- iter: 22500/22500\n",
      "--\n",
      "[[  3.49677750e-03   9.96503234e-01]\n",
      " [  1.32303648e-02   9.86769676e-01]\n",
      " [  6.19352423e-03   9.93806481e-01]\n",
      " ..., \n",
      " [  8.70228469e-01   1.29771590e-01]\n",
      " [  9.60418165e-01   3.95818911e-02]\n",
      " [  3.34767319e-05   9.99966502e-01]]\n"
     ]
    }
   ],
   "source": [
    "########## Ready to build the network with train and test data #########\n",
    "\n",
    "net = tflearn.input_data([None, 100])\n",
    "net = tflearn.embedding(net, input_dim=input_dim, output_dim=128)\n",
    "net = tflearn.lstm(net, 128, dropout=0.8)\n",
    "net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "net = tflearn.regression(net, optimizer='adam', learning_rate=0.001, loss='categorical_crossentropy')\n",
    "\n",
    "# Training\n",
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "model.fit(trainX[:22500], trainY[:22500], validation_set=(trainX[22500:], trainY[22500:]), show_metric=True, batch_size=16)\n",
    "\n",
    "predictions = model.predict(trainX)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./test1.txt', './test.txt']\n",
      "[[73, 546, 64798, 64799, 64800, 64801, 956, 30365, 64802, 3178, 993, 14695, 6, 10, 23774, 13615, 99, 191, 2036, 77, 12553, 39, 54, 2, 10157, 2190, 2, 217, 10597, 51, 20792, 30365, 14651, 2, 10, 1664, 1486, 1062, 323, 64, 6382, 217, 133, 217, 1619, 73, 64803, 51, 10, 878, 1438, 73, 2400, 34424, 32860, 962, 950, 39575, 6, 217, 3245, 14784, 10, 1664, 5, 24582, 39, 1848, 13160, 2753, 51, 10, 833, 1336, 1224, 73, 10, 380, 29344, 9, 878, 26736, 281, 1000, 37404, 5460, 13994, 29, 34424, 4878, 44, 11072, 6, 217, 4840, 51, 217, 12103, 323, 217, 7338, 617, 5, 10168, 6, 26, 472, 17372, 66, 1720, 577, 10, 1664, 51, 523, 25, 452, 2, 30365, 2, 3224, 10, 16615, 1530, 51, 2, 3931, 217, 64804, 73, 10, 1902, 5166, 173, 6208, 59266, 57900, 64805, 51, 6208, 64806, 64806, 57900, 64799, 2608, 168, 64807, 758, 5, 22, 8, 996, 26, 1684, 3256, 36, 187, 551, 12753, 1703, 29, 1324, 10, 202, 9, 4, 2608, 168, 825, 555, 1616, 87, 758, 16213, 314, 89, 16120, 92, 309, 30844, 64808, 9980, 47328, 51, 10, 814, 5, 3839, 2293, 128, 66, 567, 3377, 2, 877, 61798, 208, 787, 389, 108, 8, 80, 13156, 73, 1000, 1226, 201, 129, 225, 1036, 144, 1011, 73, 17929, 9, 51, 2564, 8660, 12, 51, 904, 5, 8, 877, 417, 4662, 32657, 406, 407, 1047, 10, 202, 9, 64807, 719, 166, 108, 3091, 33, 877, 26, 3276, 29, 1097, 31, 66, 962, 33, 10, 3831, 9, 26, 1864, 3928, 73, 26, 261, 4398, 1047, 10, 12, 198, 1292, 7297, 5, 10, 822, 144, 31, 51473, 25986, 471, 3, 2, 2485, 128, 238, 169, 399, 321, 760, 144, 10, 3669, 5484, 5, 166, 2, 54501, 5896, 989, 6, 64799, 2681, 12, 51, 6, 7203, 25560, 4, 2608, 8, 128, 238, 1943, 14724, 144, 64809, 1445, 73, 26, 903, 290, 84, 1445, 73, 191, 64810, 208, 84, 1445, 144, 1320, 1751, 238, 3978, 690, 15457, 393, 10, 1902, 8782, 824, 10, 3101, 64811, 8113, 64, 3298, 2, 24874, 191, 2193, 2, 10, 1888, 25, 4203, 2, 4890, 61, 12576, 191, 2945, 129, 2293, 30365, 51, 34424, 989, 15232, 51, 3412, 2293, 19, 371, 291, 391, 31, 10, 380, 261, 449, 4339, 2772, 5, 187, 3799, 51, 5325, 968, 153, 10, 168, 64809, 719, 291, 64, 12373, 2, 191, 30227, 53443, 64812, 18978, 36, 64807, 29, 2468, 5, 144, 10, 222, 460, 27200, 9954, 51, 64813, 73, 144, 168, 83, 314, 9954, 51, 28674, 73, 6208, 59266, 57900, 64805, 5, 437, 449, 78, 877, 7154, 5094, 437, 413, 449, 1, 693, 399, 9, 10, 1902, 16846, 173, 30365, 51, 34424, 73, 64807, 309, 24190, 78, 31103, 51, 34410, 30365, 51, 34424, 129, 66, 5832, 51, 64814, 26, 168, 144, 8197, 178, 17983, 22, 2214, 2, 52129, 25, 23, 10, 6204, 4218, 26, 8617, 9, 64815, 4040, 144, 198, 931, 64816, 10, 12, 64817, 230, 29, 127, 19, 78, 2, 7648, 66, 8, 222, 2, 2902, 1114, 64807, 58, 1011, 39, 68, 25, 437, 440, 166, 101, 19, 238, 3377, 2, 679, 9, 10, 208, 787, 41223, 64799, 23, 2, 221, 1047, 64807, 142, 497, 945, 144, 26, 903, 290, 33, 4, 5, 296, 399, 201, 2035, 29, 440, 26, 211, 6322, 19, 392, 178, 497, 68, 10, 41774, 28674, 9, 6208, 59266, 57900, 59267, 497, 68, 10, 3143, 9954, 9, 30227, 53443, 64812, 568, 314, 478, 144, 42507, 16824, 9980, 9, 6208, 64806, 64806, 57900, 29, 1016, 68, 471, 689, 63458, 128, 390, 221, 22517, 2141, 176, 73, 1107, 4, 1288, 64807], [19, 66, 868, 436, 4, 120, 51, 19, 234, 143, 144, 19, 434, 178, 91198, 391, 31, 434, 6162, 10, 37, 10, 208, 10, 23, 26, 505, 1318, 787, 5207, 153, 10822, 43, 10493, 2, 59, 934, 191, 6789, 234, 117, 10179, 19, 275, 166, 478, 94, 4051, 555, 4, 168, 39, 1967, 9, 4072, 378, 31, 5, 10, 52756, 91199, 36, 9822, 98, 51, 1099, 91200, 51, 5046, 29, 10994, 33099, 10556, 26, 1318, 26592, 51, 8474, 133, 3503, 787, 660, 26, 2672, 3614, 2, 117, 26, 7200, 133, 10, 1783, 9694, 4829, 51, 26, 2343, 2, 10, 35998, 9873, 853, 84, 6707, 10, 82550, 787, 129, 1323, 10197, 144, 12736, 91201, 116, 117, 10179, 9, 51, 10, 1119, 24608, 51, 191, 555, 91202, 787, 1910, 1579, 26, 13119, 689, 1119, 287, 9113, 10, 82550, 51, 1695, 316, 153, 26, 2932, 8234, 1299, 36, 19937, 13281, 33, 76211, 51, 635, 1465, 1036, 51, 689, 2182, 153, 8, 3411, 4013, 10254, 5046, 3756, 198, 1688, 5, 2, 1799, 9851, 26, 878, 956, 5, 10, 8, 2, 2341, 1000, 43166, 2993, 26, 2932, 91203, 26, 15161, 2314, 51, 26, 5006, 8824, 173, 0, 173, 26, 98, 211, 3068, 144, 127, 31, 78, 44, 6632, 449, 275, 108, 549, 31, 153, 26, 45973, 5026, 51, 2421, 31, 133, 141, 16, 5026, 3607, 10, 1487, 129, 16, 735, 10, 389, 531, 4, 133, 1619, 2916, 51, 635, 15041, 144, 1032, 26, 727, 2, 134, 12584, 16808, 251, 51, 181, 4, 36, 26, 1318, 83, 22, 134, 2090, 51, 2488, 448, 19, 234, 1391, 144, 10, 93, 434, 26, 17551, 1148, 1001, 51, 166, 2194, 178, 18685, 91204]]\n",
      "[[73, 546, 0, 0, 0, 0, 956, 0, 0, 3178, 993, 0, 6, 10, 0, 0, 99, 191, 2036, 77, 0, 39, 54, 2, 0, 2190, 2, 217, 0, 51, 0, 0, 0, 2, 10, 1664, 1486, 1062, 323, 64, 6382, 217, 133, 217, 1619, 73, 0, 51, 10, 878, 1438, 73, 2400, 0, 0, 962, 950, 0, 6, 217, 3245, 0, 10, 1664, 5, 0, 39, 1848, 0, 2753, 51, 10, 833, 1336, 1224, 73, 10, 380, 0, 9, 878, 0, 281, 1000, 0, 5460, 0, 29, 0, 4878, 44, 0, 6, 217, 4840, 51, 217, 0, 323, 217, 7338, 617, 5, 0, 6, 26, 472, 0, 66, 1720, 577, 10, 1664, 51, 523, 25, 452, 2, 0, 2, 3224, 10, 0, 1530, 51, 2, 3931, 217, 0, 73, 10, 1902, 5166, 173, 6208, 0, 0, 0, 51, 6208, 0, 0, 0, 0, 2608, 168, 0, 758, 5, 22, 8, 996, 26, 1684, 3256, 36, 187, 551, 0, 1703, 29, 1324, 10, 202, 9, 4, 2608, 168, 825, 555, 1616, 87, 758, 0, 314, 89, 0, 92, 309, 0, 0, 9980, 0, 51, 10, 814, 5, 3839, 2293, 128, 66, 567, 3377, 2, 877, 0, 208, 787, 389, 108, 8, 80, 0, 73, 1000, 1226, 201, 129, 225, 1036, 144, 1011, 73, 0, 9, 51, 2564, 8660, 12, 51, 904, 5, 8, 877, 417, 4662, 0, 406, 407, 1047, 10, 202, 9, 0, 719, 166, 108, 3091, 33, 877, 26, 3276, 29, 1097, 31, 66, 962, 33, 10, 3831, 9, 26, 1864, 3928, 73, 26, 261, 4398, 1047, 10, 12, 198, 1292, 7297, 5, 10, 822, 144, 31, 0, 0, 471, 3, 2, 2485, 128, 238, 169, 399, 321, 760, 144, 10, 3669, 5484, 5, 166, 2, 0, 5896, 989, 6, 0, 2681, 12, 51, 6, 7203, 0, 4, 2608, 8, 128, 238, 1943, 0, 144, 0, 1445, 73, 26, 903, 290, 84, 1445, 73, 191, 0, 208, 84, 1445, 144, 1320, 1751, 238, 3978, 690, 0, 393, 10, 1902, 8782, 824, 10, 3101, 0, 8113, 64, 3298, 2, 0, 191, 2193, 2, 10, 1888, 25, 4203, 2, 4890, 61, 0, 191, 2945, 129, 2293, 0, 51, 0, 989, 0, 51, 3412, 2293, 19, 371, 291, 391, 31, 10, 380, 261, 449, 4339, 2772, 5, 187, 3799, 51, 5325, 968, 153, 10, 168, 0, 719, 291, 64, 0, 2, 191, 0, 0, 0, 0, 36, 0, 29, 2468, 5, 144, 10, 222, 460, 0, 9954, 51, 0, 73, 144, 168, 83, 314, 9954, 51, 0, 73, 6208, 0, 0, 0, 5, 437, 449, 78, 877, 7154, 5094, 437, 413, 449, 1, 693, 399, 9, 10, 1902, 0, 173, 0, 51, 0, 73, 0, 309, 0, 78, 0, 51, 0, 0, 51, 0, 129, 66, 5832, 51, 0, 26, 168, 144, 8197, 178, 0, 22, 2214, 2, 0, 25, 23, 10, 6204, 4218, 26, 8617, 9, 0, 4040, 144, 198, 931, 0, 10, 12, 0, 230, 29, 127, 19, 78, 2, 7648, 66, 8, 222, 2, 2902, 1114, 0, 58, 1011, 39, 68, 25, 437, 440, 166, 101, 19, 238, 3377, 2, 679, 9, 10, 208, 787, 0, 0, 23, 2, 221, 1047, 0, 142, 497, 945, 144, 26, 903, 290, 33, 4, 5, 296, 399, 201, 2035, 29, 440, 26, 211, 6322, 19, 392, 178, 497, 68, 10, 0, 0, 9, 6208, 0, 0, 0, 497, 68, 10, 3143, 9954, 9, 0, 0, 0, 568, 314, 478, 144, 0, 0, 9980, 9, 6208, 0, 0, 0, 29, 1016, 68, 471, 689, 0, 128, 390, 221, 0, 2141, 176, 73, 1107, 4, 1288, 0], [19, 66, 868, 436, 4, 120, 51, 19, 234, 143, 144, 19, 434, 178, 0, 391, 31, 434, 6162, 10, 37, 10, 208, 10, 23, 26, 505, 1318, 787, 5207, 153, 0, 43, 0, 2, 59, 934, 191, 6789, 234, 117, 0, 19, 275, 166, 478, 94, 4051, 555, 4, 168, 39, 1967, 9, 4072, 378, 31, 5, 10, 0, 0, 36, 9822, 98, 51, 1099, 0, 51, 5046, 29, 0, 0, 0, 26, 1318, 0, 51, 8474, 133, 3503, 787, 660, 26, 2672, 3614, 2, 117, 26, 7200, 133, 10, 1783, 9694, 4829, 51, 26, 2343, 2, 10, 0, 9873, 853, 84, 6707, 10, 0, 787, 129, 1323, 0, 144, 0, 0, 116, 117, 0, 9, 51, 10, 1119, 0, 51, 191, 555, 0, 787, 1910, 1579, 26, 0, 689, 1119, 287, 9113, 10, 0, 51, 1695, 316, 153, 26, 2932, 8234, 1299, 36, 0, 0, 33, 0, 51, 635, 1465, 1036, 51, 689, 2182, 153, 8, 3411, 4013, 0, 5046, 3756, 198, 1688, 5, 2, 1799, 9851, 26, 878, 956, 5, 10, 8, 2, 2341, 1000, 0, 2993, 26, 2932, 0, 26, 0, 2314, 51, 26, 5006, 8824, 173, 0, 173, 26, 98, 211, 3068, 144, 127, 31, 78, 44, 6632, 449, 275, 108, 549, 31, 153, 26, 0, 5026, 51, 2421, 31, 133, 141, 16, 5026, 3607, 10, 1487, 129, 16, 735, 10, 389, 531, 4, 133, 1619, 2916, 51, 635, 0, 144, 1032, 26, 727, 2, 134, 0, 0, 251, 51, 181, 4, 36, 26, 1318, 83, 22, 134, 2090, 51, 2488, 448, 19, 234, 1391, 144, 10, 93, 434, 26, 0, 1148, 1001, 51, 166, 2194, 178, 0, 0]]\n",
      "[[  4.67235111e-02   9.53276455e-01]\n",
      " [  9.99137998e-01   8.61937646e-04]]\n"
     ]
    }
   ],
   "source": [
    "testing_1 = glob.glob('./test*.txt')\n",
    "print testing_1\n",
    "testing_1 = get_data(testing_1)\n",
    "print testing_1\n",
    "for i in range(len(testing_1)) :\n",
    "    testing_1[i] = [x if x in top else 0 for x in testing_1[i]]\n",
    "print testing_1\n",
    "testing_1 = pad_sequences(testing_1, maxlen=100, value=0.)\n",
    "print(model.predict(testing_1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
